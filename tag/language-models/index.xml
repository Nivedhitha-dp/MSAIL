<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Language Models | MSAIL</title>
    <link>https://MSAIL.github.io/tag/language-models/</link>
      <atom:link href="https://MSAIL.github.io/tag/language-models/index.xml" rel="self" type="application/rss+xml" />
    <description>Language Models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 30 Mar 2021 18:00:00 -0400</lastBuildDate>
    <image>
      <url>https://MSAIL.github.io/media/logo.png</url>
      <title>Language Models</title>
      <link>https://MSAIL.github.io/tag/language-models/</link>
    </image>
    
    <item>
      <title>Harmful Bias in Natural Language Generation</title>
      <link>https://MSAIL.github.io/talk/harmful_bias_nlg/</link>
      <pubDate>Tue, 30 Mar 2021 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/harmful_bias_nlg/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: Yashmeet Gambhir&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: Harmful Bias in Natural Language Generation&lt;/p&gt;
&lt;p&gt;Large language models have taken over the NLP scene and have led to a surge of state-of-art development in natural language generation tasks (machine translation, story generation, chatbots, etc.). However, these models have been shown to reflect many harmful societal biases that exist in text around the internet. This talk will go over two major papers studying harmful bias in large LMs: the first identifies and quantifies this bias, the second will attempt to mitigate bias.&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Papers:&lt;/strong&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/abs/1909.01326&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Woman worked as a Babysitter: On Biases in Language Generation&lt;/a&gt;

&lt;a href=&#34;https://www.aclweb.org/anthology/2020.findings-emnlp.291.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards Controllable Biases in Language Generation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Transformers for Vision</title>
      <link>https://MSAIL.github.io/talk/image-worth-16x16-words/</link>
      <pubDate>Tue, 09 Mar 2021 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/image-worth-16x16-words/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: Andrew Awad and Drake Svoboda&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: Using Transformers for Computer Vision&lt;/p&gt;
&lt;p&gt;In recent years we&amp;rsquo;ve seen the rise of transformers in natural language processing research, burgeoning the field to incredible heights. However, these very same transformers were seldom applied to computer vision tasks until recently. Andrew and Drake discussed how transformers have been used in vision tasks in recent years in a presentation covering two papers. The first, An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (via Google Brain), is the &amp;ldquo;Attention is All You Need&amp;rdquo; of vision. Namely, this paper covers how one can construct a vision architecture devoid of the commonly applied CNN and still achieve comparable or better performance results while possibly cutting down computing resources. The second paper, End-to-End Object Detection with Transformers (via FAIR), formalizes the object detection task in a unique way that affords the usage of transformers.&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Papers:&lt;/strong&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/pdf/2010.11929.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/pdf/2005.12872.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;End-to-End Object Detection with Transformers&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Proving Theorems with Generative Language Models</title>
      <link>https://MSAIL.github.io/talk/generative_language_modeling/</link>
      <pubDate>Mon, 01 Mar 2021 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/generative_language_modeling/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: Ashwin Sreevatsa&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: Generative Language Modeling for Automated Theorem Proving Presentation&lt;/p&gt;
&lt;p&gt;In the past decade, deep learning and artificial neural networks have been incredibly successful at a variety of tasks such as computer vision, translation, game playing, and robotics among others. However, there have been less examples of deep learning making progress with reasoning related tasks- such as automated theorem proving, the task of proving mathematical theorems using computer programs. This paper explores the use of transformer-based models to automated theorem proving and presents GPT-f, a deep learning-based automated prover and proof assistant.&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Papers:&lt;/strong&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/pdf/2009.03393.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generative Language Modeling for Automated Theorem Proving Presentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Trend Towards Large Language Models</title>
      <link>https://MSAIL.github.io/talk/gpt3_091520/</link>
      <pubDate>Tue, 15 Sep 2020 18:00:00 -0400</pubDate>
      <guid>https://MSAIL.github.io/talk/gpt3_091520/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Speaker(s)&lt;/strong&gt;: Sean Stapleton&lt;br&gt;
&lt;strong&gt;Topic&lt;/strong&gt;: GPT-3 and its Implications&lt;/p&gt;
&lt;p&gt;In recent years, weâ€™ve seen 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Natural_language_processing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;natural language processing&lt;/a&gt; (NLP) performance accelerate drastically across a number of tasks, including text completion, 
&lt;a href=&#34;https://paperswithcode.com/task/machine-translation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;machine translation&lt;/a&gt;, and 
&lt;a href=&#34;https://paperswithcode.com/task/question-answering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;question answering&lt;/a&gt;. Much of this performance gain has been attributed to two trends in the NLP community, namely the introduction of transformers, and the increase in model size (and consequent need for intense computational power). Capitalizing on these trends, 
&lt;a href=&#34;https://openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI&lt;/a&gt; recently released a transformer-based model called 
&lt;a href=&#34;https://en.wikipedia.org/wiki/gpt-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-3&lt;/a&gt; with 175 billion parameters, that was trained on roughly 500 billion tokens scraped from the internet.
This MSAIL discussion focused predominantly on three questions addressed in the paper:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Does a substantial increase in model size actually lead to better performance in downstream tasks?&lt;/li&gt;
&lt;li&gt;Can language models effectively model intelligent and adaptable thought?&lt;/li&gt;
&lt;li&gt;What are the biases and risks associated with training a language model on the entire internet?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sean also covered the transformer and GPT-3 model architectures, though the focus of the discussion was not on this aspect of the paper.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://drive.google.com/file/d/12beS3Er1AuiCbmxNR0rAiiot43xTkw_n/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;You can find the recording of this talk here.&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;supplemental-resources&#34;&gt;Supplemental Resources&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Papers:&lt;/strong&gt;&lt;br&gt;

&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Language Models are Few-Shot Learners (Brown et al.)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Articles:&lt;/strong&gt;&lt;br&gt;

&lt;a href=&#34;http://jalammar.github.io/illustrated-transformer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Illustrated Transformer&lt;/a&gt;&lt;br&gt;

&lt;a href=&#34;http://jalammar.github.io/illustrated-gpt2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Illustrated GPT-2&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
